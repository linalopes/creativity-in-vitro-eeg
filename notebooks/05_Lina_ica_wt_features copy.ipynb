{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from mne.preprocessing import ICA\n",
    "from mne_icalabel import label_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1\n",
      "MPS available? True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"MPS available?\", torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config ‚Äî paths & processing constants  \n",
    "\n",
    "All hard-coded parameters live in one place so you (or a colleague) can\n",
    "re-run the notebook on another machine by editing a single cell.\n",
    "\n",
    "* **paths** ‚Äì BIDS root and sub-folders inside `derivatives/`\n",
    "* **data**  ‚Äì recording constants reused later (montage, sfreq, etc.)\n",
    "* **ica**   ‚Äì method & hyper-params; change here to compare algorithms\n",
    "* **reject** ‚Äì thresholds that tag bad ICs automatically\n",
    "* **features** ‚Äì what spectral bands & window length to extract\n",
    "* **model** ‚Äì a first classifier + CV split; purely exploratory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded ‚Äì ready for ICA & features üöÄ\n"
     ]
    }
   ],
   "source": [
    "CONFIG = dict(\n",
    "\n",
    "    # ---------- paths ----------------------------------------------------\n",
    "    paths = dict(\n",
    "        bids_root   = Path(\"../bids_dataset\"),\n",
    "        deriv_root  = Path(\"../bids_dataset/derivatives\"),\n",
    "        filt_dir    = Path(\"../bids_dataset/derivatives/filt_crop\"),\n",
    "        ica_dir     = Path(\"../bids_dataset/derivatives/ica_clean\"),\n",
    "        feat_dir    = Path(\"../bids_dataset/derivatives/features\")\n",
    "    ),\n",
    "\n",
    "    # ---------- recording constants --------------------------------------\n",
    "    data = dict(\n",
    "        sfreq       = 125.0,                      # Hz\n",
    "        eeg_ch      = [\"Fp1\",\"Fp2\",\"C3\",\"C4\",\"T7\",\"T8\",\n",
    "                       \"O1\",\"O2\",\"F3\",\"F4\",\"Fz\",\"Pz\",\"P3\",\"P4\"],\n",
    "        montage     = \"standard_1020\",\n",
    "        n_blocks    = 20,\n",
    "    ),\n",
    "\n",
    "    # ---------- ICA parameters -------------------------------------------\n",
    "    ica = dict(\n",
    "        method         = \"picard\",    # \"fastica\" | \"picard\" | \"infomax\"\n",
    "        n_components   = 0.99,        # keep 99 % of variance\n",
    "        random_state   = 42,\n",
    "        max_iter       = 500,\n",
    "        decim          = 3            # speed-up; 125/3 ‚âà 42 Hz\n",
    "    ),\n",
    "\n",
    "    # ---------- auto-reject thresholds (z-score in IC space) -------------\n",
    "    reject = dict(\n",
    "        eog_z     = 3.0,     # eye blinks\n",
    "        emg_z     = 3.0,     # muscle\n",
    "        slow_z    = 3.0      # slow drifts\n",
    "    ),\n",
    "\n",
    "    # ---------- feature extraction ---------------------------------------\n",
    "    features = dict(\n",
    "        bands   = {\"delta\":(1,4), \"theta\":(4,8),\n",
    "                   \"alpha\":(8,13), \"beta\":(13,30),\n",
    "                   \"gamma\":(30,45)},\n",
    "        win_sec     = 2.0,   # sliding-window length\n",
    "        step_sec    = 0.5,\n",
    "        wavelet_levels = 6\n",
    "    ),\n",
    "\n",
    "    # ---------- first classifier to prototype ----------------------------\n",
    "    model = dict(\n",
    "        clf          = \"lightgbm\",   # or \"svm\"\n",
    "        cv_folds     = 5,\n",
    "        test_size    = 0.2\n",
    "    ),\n",
    ")\n",
    "\n",
    "# create sub-folders if they don‚Äôt exist\n",
    "for p in CONFIG[\"paths\"].values():\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Config loaded ‚Äì ready for ICA & features üöÄ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the 20 filtered & cropped blocks\n",
    "\n",
    "Before any additional processing we first bring the twenty pre-filtered /\n",
    "cropped recordings into memory.  \n",
    "At this stage **projectors remain OFF** so the data are identical to the files\n",
    "written by 04_Lina_restart_with_MNE (`*_flt-crop_raw.fif`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading blk00_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk01_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk02_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk03_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk04_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk05_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk06_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk07_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk08_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk09_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk10_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk11_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk12_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk13_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk14_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk15_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk16_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk17_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk18_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "Reading blk19_flt-crop_raw.fif ‚Ä¶ ‚úì\n",
      "\n",
      "Loaded 20 blocks. Projectors are currently OFF.\n"
     ]
    }
   ],
   "source": [
    "# Gather the expected *.fif files\n",
    "blk_paths = sorted(\n",
    "    CONFIG[\"paths\"][\"filt_dir\"].glob(\"blk??_flt-crop_raw.fif\")\n",
    ")\n",
    "assert len(blk_paths) == CONFIG[\"data\"][\"n_blocks\"], (\n",
    "    f\"Expected {CONFIG['data']['n_blocks']} blocks, found {len(blk_paths)}.\"\n",
    ")\n",
    "\n",
    "raw_blocks = []\n",
    "for fpath in blk_paths:\n",
    "    print(f\"Reading {fpath.name} ‚Ä¶\", end=\" \")\n",
    "    raw = mne.io.read_raw_fif(fpath, preload=True, verbose=False)\n",
    "    raw_blocks.append(raw)\n",
    "    print(\"‚úì\")\n",
    "\n",
    "print(f\"\\nLoaded {len(raw_blocks)} blocks. Projectors are currently OFF.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a ¬∑ Why we switch **ON** the average-reference projection\n",
    "\n",
    "Each `.fif` block already contains a *projector* that re-references the data to\n",
    "the **common average** (CAR).  Up to this point we kept that projector **OFF**\n",
    "to ensure the raw voltages from the previous notebook were preserved during\n",
    "filtering/cropping.  Turning the projector **ON** now is critical for three\n",
    "reasons:\n",
    "\n",
    "1. **Signal centring**   \n",
    "   Referencing every channel to the grand mean neutralises slow offsets caused\n",
    "   by unequal electrode impedances or amplifier drift.  This flattens the\n",
    "   baseline and yields cleaner butterfly plots and topomaps.\n",
    "\n",
    "2. **Better ICA decomposition**   \n",
    "   ICA assumes that sources mix *linearly* and with zero-mean time courses.\n",
    "   Applying the CAR before decomposition improves the separation of ocular,\n",
    "   cardiac and myogenic components, making automatic IC labelling more\n",
    "   reliable.\n",
    "\n",
    "3. **Pipeline consistency**   \n",
    "   Most EEG-to-text decoding papers perform ICA on average-referenced data.\n",
    "   Activating the projector now keeps our workflow aligned with that\n",
    "   literature and prevents accidental mixing of referenced and\n",
    "   non-referenced epochs later on.\n",
    "\n",
    "> **Note:** `raw.apply_proj()` is *idempotent*‚Äîonce the projector is applied,\n",
    "> calling it again will have no additional effect as the projection matrix is\n",
    "> removed from `raw.info[\"projs\"]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ  Average-reference projection applied to 20 blocks.\n"
     ]
    }
   ],
   "source": [
    "for idx, raw in enumerate(raw_blocks):\n",
    "    if not raw.info[\"projs\"]:\n",
    "        raise RuntimeError(f\"Block {idx:02d} has no projector defined.\")\n",
    "    raw.apply_proj(verbose=False)\n",
    "\n",
    "print(f\"‚úÖ  Average-reference projection applied to {len(raw_blocks)} blocks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where does the stored **common-average reference (CAR)** come from?\n",
    "\n",
    "The projector you see inside each `Raw` file was created in the previous notebook (the\n",
    "pre-processing stage) with the following single line of MNE-Python:\n",
    "\n",
    "```python\n",
    "raw.set_eeg_reference(\"average\", projection=True)\n",
    "````\n",
    "\n",
    "**Why defer application?**\n",
    "\n",
    "Filtering, notch removal, and cropping were performed on the original voltage\n",
    "scale to avoid numerical artefacts that can arise when the reference itself is\n",
    "filtered. By postponing the CAR we ensure it touches the already-cleaned\n",
    "signal only once, making the operation idempotent.\n",
    "\n",
    "So, the CAR originates entirely from this offline MNE call‚Äînothing was changed\n",
    "on the OpenBCI Cyton hardware during acquisition. The headset‚Äôs built-in bias\n",
    "drive delivered a common electrode reference while recording; the average\n",
    "reference we apply now is purely a software construct saved inside each\n",
    ".fif file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ICA cleaning with Picard and automatic component rejection\n",
    "\n",
    "With all blocks now average-referenced, the next step is to remove ocular,\n",
    "muscular, cardiac, and line-noise artefacts via **Independent Component\n",
    "Analysis (ICA)**.  We adopt the following design:\n",
    "\n",
    "| Choice | Value | Rationale |\n",
    "|--------|-------|-----------|\n",
    "| *Algorithm* | **Picard** (`method=\"picard\"`) | Fast and deterministic when seeded, converges reliably on small channel counts. |\n",
    "| *Number of components* | `n_components = 0.99` | Keep enough PCs to explain ‚â• 99 % variance while discarding tiny noise dimensions. |\n",
    "| *Sample thinning* | `decim = 2` (training at ~62.5 Hz) | Avoids aliasing of our 1‚Äì45 Hz pass-band and gives ~2√ó speed-up over full-rate fitting. |\n",
    "| *Auto-labelling* | `mne_icalabel` if available; fallback to `find_bads_eog/muscle` with z-scores in `CONFIG[\"reject\"]` | Fully reproducible; manual tweaks can follow in the QA report. |\n",
    "| *Output files* | Cleaned `Raw`  ‚Üí `ica_clean/blk##_icaclean_raw.fif`<br>ICA object ‚Üí `ica_clean/blk##_ica.fif` | Keeps both the processed data and the unmixing matrix for later inspection. |\n",
    "\n",
    "The cleaned signals will still be stored at the **original 125 Hz**, because\n",
    "the unmixing matrix learned on the thinned data is applied to the full-rate\n",
    "recordings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ  Sanity check passed for all blocks.\n"
     ]
    }
   ],
   "source": [
    "for raw in raw_blocks:\n",
    "    assert raw.proj     , \"CAR not applied?\"\n",
    "    assert raw.info['sfreq'] == 125.0, \"Unexpected sampling rate!\"\n",
    "\n",
    "print(\"‚úÖ  Sanity check passed for all blocks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Block blk00: fitting ICA ‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ny/tk1xvwsn7n11pkl0vlgl1sz80000gn/T/ipykernel_3102/928001962.py:28: RuntimeWarning: The provided Raw instance does not seem to be referenced to a common average reference (CAR). ICLabel was designed to classify features extracted from an EEG dataset referenced to a CAR (see the 'set_eeg_reference()' method for Raw and Epochs instances).\n",
      "  out      = label_components(raw, ica, method=\"iclabel\")\n",
      "/var/folders/ny/tk1xvwsn7n11pkl0vlgl1sz80000gn/T/ipykernel_3102/928001962.py:28: RuntimeWarning: The provided Raw instance is not filtered between 1 and 100 Hz. ICLabel was designed to classify features extracted from an EEG dataset bandpass filtered between 1 and 100 Hz (see the 'filter()' method for Raw and Epochs instances).\n",
      "  out      = label_components(raw, ica, method=\"iclabel\")\n",
      "/var/folders/ny/tk1xvwsn7n11pkl0vlgl1sz80000gn/T/ipykernel_3102/928001962.py:28: RuntimeWarning: The provided ICA instance was fitted with a 'picard' algorithm. ICLabel was designed with extended infomax ICA decompositions. To use the extended infomax algorithm, use the 'mne.preprocessing.ICA' instance with the arguments 'ICA(method='infomax', fit_params=dict(extended=True))' (scikit-learn) or 'ICA(method='picard', fit_params=dict(ortho=False, extended=True))' (python-picard).\n",
      "  out      = label_components(raw, ica, method=\"iclabel\")\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m labels   \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     30\u001b[0m proba    \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 31\u001b[0m classes  \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclasses\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m            \u001b[38;5;66;03m# ['brain', 'muscle', ‚Ä¶]\u001b[39;00m\n\u001b[1;32m     33\u001b[0m exclude_idx \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     34\u001b[0m     i \u001b[38;5;28;01mfor\u001b[39;00m i, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(labels)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lab \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meye\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmuscle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheart\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mline_noise\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m proba[i, classes\u001b[38;5;241m.\u001b[39mindex(lab)] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m THRESH\n\u001b[1;32m     37\u001b[0m ]\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    ICLabel ‚Üí excluding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexclude_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (prob ‚â• \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTHRESH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'classes'"
     ]
    }
   ],
   "source": [
    "ica_dir = CONFIG[\"paths\"][\"ica_dir\"]\n",
    "\n",
    "# Loop over the 20 blocks already loaded in raw_blocks\n",
    "for idx, (raw, in_path) in enumerate(zip(raw_blocks, CONFIG[\"paths\"][\"filt_dir\"].glob(\"blk??_flt-crop_raw.fif\"))):\n",
    "    blk_id = f\"{idx:02d}\"\n",
    "    print(f\"\\n### Block {blk_id}: fitting ICA ‚Ä¶\")\n",
    "\n",
    "    # ----- ICA set-up ------------------------------------------------------\n",
    "    ica = mne.preprocessing.ICA(\n",
    "        n_components=CONFIG[\"ica\"][\"n_components\"],\n",
    "        method=CONFIG[\"ica\"][\"method\"],\n",
    "        random_state=CONFIG[\"ica\"][\"random_state\"],\n",
    "        max_iter=CONFIG[\"ica\"][\"max_iter\"],\n",
    "    )\n",
    "\n",
    "    # ----- Fit (decimated copy) -------------------------------------------\n",
    "    ica.fit(raw, decim=CONFIG[\"ica\"][\"decim\"], verbose=\"error\")\n",
    "\n",
    "    # ----- Automatic component labelling ----------------------------------\n",
    "    exclude_idx = []\n",
    "    try:\n",
    "        from mne_icalabel import label_components\n",
    "\n",
    "        ic_labels = label_components(raw, ica, method=\"iclabel\")[\"labels\"]\n",
    "        exclude_idx = [\n",
    "            i for i, lab in enumerate(ic_labels)\n",
    "            if lab in {\"eye\", \"muscle\", \"heart\", \"line_noise\"}\n",
    "        ]\n",
    "    except ImportError:\n",
    "        # Fallback heuristic using built-ins\n",
    "        eog_inds, _ = ica.find_bads_eog(raw,\n",
    "                                        threshold=CONFIG[\"reject\"][\"eog_z\"],\n",
    "                                        verbose=False)\n",
    "        muscle_inds, _ = ica.find_bads_muscle(raw,\n",
    "                                              threshold=CONFIG[\"reject\"][\"emg_z\"],\n",
    "                                              verbose=False)\n",
    "        exclude_idx = list(set(eog_inds + muscle_inds))\n",
    "\n",
    "    ica.exclude = exclude_idx\n",
    "    print(f\"    ‚Üí Excluding components: {exclude_idx}\")\n",
    "\n",
    "    # ----- Apply and save --------------------------------------------------\n",
    "    ica.apply(raw)\n",
    "\n",
    "    # Build filenames\n",
    "    stem = Path(in_path).stem.replace(\"_flt-crop_raw\", \"\")\n",
    "    raw_out = ica_dir / f\"{stem}_icaclean_raw.fif\"\n",
    "    ica_out = ica_dir / f\"{stem}_ica.fif\"\n",
    "\n",
    "    raw.save(raw_out, overwrite=True, verbose=False)\n",
    "    ica.save(ica_out, overwrite=True)\n",
    "\n",
    "    print(f\"    Saved cleaned Raw ‚Üí {raw_out.name}\")\n",
    "    print(f\"    Saved ICA object  ‚Üí {ica_out.name}\")\n",
    "\n",
    "print(\"\\nüéâ  All 20 blocks cleaned and saved in CONFIG['paths']['ica_dir'].\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspection of ICA results (example: blk18)\n",
    "\n",
    "Below we reload both the fitted **ICA model** and the corresponding\n",
    "**cleaned Raw** for *blk18* (the penultimate block) and:\n",
    "\n",
    "1. Print a textual summary of which ICs were excluded and their labels.  \n",
    "2. Display the topomaps of the rejected components and the ‚Äúbefore vs after‚Äù\n",
    "   butterfly plot so we can verify that eye / muscle artefacts are gone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/linalopes/Desktop/creativity-in-vitro-eeg/notebooks/../bids_dataset/derivatives/ica_clean/blk18_ica.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 14) active\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Opening raw data file ../bids_dataset/derivatives/ica_clean/blk18_icaclean_raw.fif...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 14) active\n",
      "    Range : 875 ... 17538 =      7.000 ...   140.304 secs\n",
      "Ready.\n",
      "Reading 0 ... 16663  =      0.000 ...   133.304 secs...\n",
      "=== blk18  ICA summary ===\n",
      "Excluded IC indices : []\n",
      "ICLabel classes   : {'brain': [1, 2, 3, 4, 5, 6], 'muscle': [], 'eog': [0, 8], 'ecg': [], 'line_noise': [], 'ch_noise': [7], 'other': []}\n",
      "Cleaned Raw shape  : (15, 16664)  (n_ch √ó n_samples)\n"
     ]
    }
   ],
   "source": [
    "blk_idx = 18                                 # penultimate block (0-based)\n",
    "stem = f\"blk{blk_idx:02d}\"\n",
    "ica_path  = CONFIG[\"paths\"][\"ica_dir\"] / f\"{stem}_ica.fif\"\n",
    "raw_path  = CONFIG[\"paths\"][\"ica_dir\"] / f\"{stem}_icaclean_raw.fif\"\n",
    "\n",
    "ica  = mne.preprocessing.read_ica(ica_path)\n",
    "raw  = mne.io.read_raw_fif(raw_path, preload=True)  # just to know ch-names\n",
    "\n",
    "print(f\"=== {stem}  ICA summary ===\")\n",
    "print(\"Excluded IC indices :\", ica.exclude)\n",
    "try:\n",
    "    print(\"ICLabel classes   :\", ica.labels_)  # added by label_components\n",
    "except AttributeError:\n",
    "    print(\"No 'labels_' attr ‚Üí ICLabel not run / not saved.\")\n",
    "\n",
    "print(f\"Cleaned Raw shape  : {raw._data.shape}  (n_ch √ó n_samples)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median peak-to-peak: 2.40 ¬µV\n"
     ]
    }
   ],
   "source": [
    "# peak-to-peak (¬µV) for each EEG channel\n",
    "data_uV = raw_orig.get_data(picks=\"eeg\") * 1e6        # V ‚Üí ¬µV\n",
    "pp      = np.ptp(data_uV, axis=1)                     # <- use np.ptp()\n",
    "median_pp = np.median(pp)\n",
    "\n",
    "print(f\"Median peak-to-peak: {median_pp:.2f} ¬µV\")\n",
    "\n",
    "scale_val = (median_pp / 2) * 1e-6    # back to volts per division\n",
    "scale = dict(eeg=scale_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file ../bids_dataset/derivatives/filt_crop/blk18_flt-crop_raw.fif...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 14)  idle\n",
      "    Range : 875 ... 17538 =      7.000 ...   140.304 secs\n",
      "Ready.\n",
      "Reading 0 ... 16663  =      0.000 ...   133.304 secs...\n",
      "Using pyopengl with version 3.1.9\n",
      "Applying ICA to Raw instance\n",
      "    Applying projection operator with 1 vector (pre-whitener application)\n",
      "    Transforming to ICA space (9 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 14 PCA components\n",
      "Using pyopengl with version 3.1.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "# Visual sanity checks for blk18\n",
    "\n",
    "# --- Topomaps of rejected ICs -------------------------------------------\n",
    "if ica.exclude:\n",
    "    ica.plot_components(picks=ica.exclude, title=f\"{stem} ‚Äì rejected ICs\",\n",
    "                        show=True)\n",
    "\n",
    "# --- Butterfly before vs after ------------------------------------------\n",
    "# Load the original filtered/cropped (but *not* ICA-cleaned) data\n",
    "orig_path = CONFIG[\"paths\"][\"filt_dir\"] / f\"{stem}_flt-crop_raw.fif\"\n",
    "raw_orig  = mne.io.read_raw_fif(orig_path, preload=True)\n",
    "\n",
    "fig1 = raw_orig.plot(title=f\"{stem} ‚Äì BEFORE ICA  (custom scale)\",\n",
    "                     scalings=scale, show=True)\n",
    "\n",
    "fig2 = ica.apply(raw_orig.copy(), exclude=ica.exclude)\\\n",
    "          .plot(title=f\"{stem} ‚Äì AFTER ICA  (custom scale)\",\n",
    "                scalings=scale, show=True)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creativity-eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
